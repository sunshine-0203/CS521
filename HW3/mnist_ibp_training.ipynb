{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBP Training on MNIST\n",
    "Implementation of IBP (Interval Bound Propagation) training using a 3-layer fully-connected ReLU network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from bound_propagation import BoundModelFactory, HyperRectangle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "\n",
    "# MNIST dataloaders\n",
    "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = 28*28\n",
    "        for _ in range(3):\n",
    "            layers.append(nn.Linear(d, 50))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            d = 50\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(d, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.body(x)\n",
    "        z = self.head(h)      # logits (NO softmax!)\n",
    "        return z\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307)/0.3081\n",
    "\n",
    "model = nn.Sequential(Normalize(), Net())\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "def adversarial_logit(bounds, y):\n",
    "    batch_size = y.size(0)\n",
    "    classes = torch.arange(10, device=y.device).unsqueeze(0).expand(batch_size, -1)\n",
    "    mask = (classes == y.unsqueeze(-1)).to(dtype=bounds.lower.dtype)\n",
    "    adv_logit = (1 - mask) * bounds.upper + mask * bounds.lower\n",
    "    return adv_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = 28 * 28\n",
    "        for _ in range(3):\n",
    "            layers.append(nn.Linear(d, 50))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            d = 50\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(d, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.body(x)\n",
    "        z = self.head(h)\n",
    "        return z\n",
    "\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307) / 0.3081\n",
    "\n",
    "\n",
    "model = nn.Sequential(Normalize(), Net()).to(device)\n",
    "\n",
    "def interval_linear(W, b, l_in, u_in):\n",
    "    W_pos = torch.clamp(W, min=0)\n",
    "    W_neg = torch.clamp(W, max=0)\n",
    "    l_out = l_in @ W_pos.T + u_in @ W_neg.T + b\n",
    "    u_out = u_in @ W_pos.T + l_in @ W_neg.T + b\n",
    "    return l_out, u_out\n",
    "\n",
    "def interval_relu(l_in, u_in):\n",
    "    return F.relu(l_in), F.relu(u_in)\n",
    "\n",
    "def interval_forward(model, x, eps):\n",
    "    \"\"\"Compute (l,u) interval bounds for final logits.\"\"\"\n",
    "    normalize = model[0]\n",
    "    net = model[1]\n",
    "\n",
    "    mean, std = 0.1307, 0.3081\n",
    "    l = torch.clamp(x - eps, 0, 1)\n",
    "    u = torch.clamp(x + eps, 0, 1)\n",
    "    l = (l - mean) / std\n",
    "    u = (u - mean) / std\n",
    "\n",
    "    l = l.view(l.size(0), -1)\n",
    "    u = u.view(u.size(0), -1)\n",
    "\n",
    "    layers = list(net.body)\n",
    "    for i in range(0, len(layers), 2):\n",
    "        linear = layers[i]\n",
    "        W, b = linear.weight, linear.bias\n",
    "        l, u = interval_linear(W, b, l, u)\n",
    "        l, u = interval_relu(l, u)\n",
    "\n",
    "    W, b = net.head.weight, net.head.bias\n",
    "    l, u = interval_linear(W, b, l, u)\n",
    "    return l, u\n",
    "\n",
    "\n",
    "def worst_case_logits_from_bounds(lz, uz, labels):\n",
    "    \"\"\"Construct worst-case logits for CE loss.\"\"\"\n",
    "    onehot = F.one_hot(labels, num_classes=lz.size(1)).bool()\n",
    "    worst_logits = torch.where(onehot, lz, uz)\n",
    "    return worst_logits\n",
    "\n",
    "def kappa_schedule(epoch, total_epochs, start=1.0, end=0.5):\n",
    "    return start - (start - end) * epoch / (total_epochs - 1)\n",
    "\n",
    "def eps_schedule(epoch, total_epochs, eps_target):\n",
    "    return eps_target * epoch / (total_epochs - 1)\n",
    "\n",
    "def train_ibp(model, train_loader, num_epochs=20, lr=1e-3, eps_train_target=0.1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        kappa = kappa_schedule(epoch, num_epochs, 1.0, 0.5)\n",
    "        eps = eps_schedule(epoch, num_epochs, eps_train_target)\n",
    "        run_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            logits_clean = model(images)\n",
    "            loss_clean = criterion(logits_clean, labels)\n",
    "\n",
    "            lz, uz = interval_forward(model, images, eps)\n",
    "            worst_logits = worst_case_logits_from_bounds(lz, uz, labels)\n",
    "            loss_ibp = criterion(worst_logits, labels)\n",
    "\n",
    "            loss = kappa * loss_clean + (1 - kappa) * loss_ibp\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            run_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] κ={kappa:.3f} ε={eps:.3f} Loss={run_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    total_time = time.time() - t0\n",
    "    print(f\"IBP training completed in {total_time:.2f} sec\")\n",
    "    return total_time\n",
    "\n",
    "\n",
    "def verify_accuracy(model, test_loader, eps):\n",
    "    model.eval()\n",
    "    verified, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            l_out, u_out = interval_forward(model, images, eps)\n",
    "            for i in range(images.size(0)):\n",
    "                true_label = labels[i].item()\n",
    "                if l_out[i, true_label] > torch.max(u_out[i, torch.arange(10) != true_label]):\n",
    "                    verified += 1\n",
    "            total += images.size(0)\n",
    "    return 100.0 * verified / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, X, y, eps=0.1, alpha=0.01, iters=20):\n",
    "    X_adv = X.clone().detach().requires_grad_(True)\n",
    "    for _ in range(iters):\n",
    "        logits = model(X_adv)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        X_adv = X_adv + alpha * X_adv.grad.sign()\n",
    "        X_adv = torch.min(torch.max(X_adv, X - eps), X + eps)\n",
    "        X_adv = X_adv.clamp(0, 1).detach().requires_grad_(True)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verified_accuracy(net, test_loader, eps_values, device='cuda'):\n",
    "    results = []\n",
    "    for eps in eps_values:\n",
    "        verified = 0\n",
    "        total = 0\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            bounds = net.ibp(HyperRectangle.from_eps(X, eps))\n",
    "            adv_logits = adversarial_logit(bounds, y)\n",
    "            pred = adv_logits.argmin(1)  # worst-case logit\n",
    "            verified += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        acc = verified / total\n",
    "        print(f\"eps={eps:.3f}, verified acc={acc:.3f}\")\n",
    "        results.append((eps, acc))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard(model, train_loader, num_epochs=20, lr=1e-3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    t0 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[STD] Epoch {epoch+1}/{num_epochs}, Loss={total_loss/len(train_loader):.4f}\")\n",
    "    return time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90de9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, loader, eps=0.1, pgd_steps=10):\n",
    "    model.eval()\n",
    "    total, correct, correct_adv = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    # PGD robust accuracy\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        adv = pgd_attack(model, x, y, eps, eps/4, pgd_steps)\n",
    "        with torch.no_grad():\n",
    "            out_adv = model(adv)\n",
    "            pred_adv = out_adv.argmax(1)\n",
    "            correct_adv += (pred_adv == y).sum().item()\n",
    "\n",
    "    std_acc = 100 * correct / total\n",
    "    rob_acc = 100 * correct_adv / total\n",
    "    return std_acc, rob_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_std = nn.Sequential(Normalize(), Net()).to(device)\n",
    "std_time = train_standard(model_std, train_loader, num_epochs=20)\n",
    "std_acc, std_rob = evaluate_accuracy(model_std, test_loader, eps=0.1)\n",
    "print(f\"\\nStandard Model: acc={std_acc:.2f}%  robust acc={std_rob:.2f}%  time={std_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in torch.linspace(0.01, 0.1, 10):\n",
    "    acc = verify_accuracy(model_std, test_loader, eps)\n",
    "    print(f\"Verified accuracy at eps={eps:.2f}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = train_ibp(model, train_loader, num_epochs=20, lr=1e-3, eps_train_target=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b18a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibp_acc, ibp_rob = evaluate_accuracy(model, test_loader, eps=0.1)\n",
    "print(f\"\\nIBP Model: acc={ibp_acc:.2f}%  robust acc={ibp_rob:.2f}%  time={train_time:.1f}s\")\n",
    "for eps in torch.linspace(0.01, 0.1, 10):\n",
    "    acc = verify_accuracy(model, test_loader, eps)\n",
    "    print(f\"Verified accuracy at eps={eps:.2f}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784168bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_adversarial_examples(model, loader, eps_list=[0.05, 0.1, 0.2]):\n",
    "    model.eval()\n",
    "    x, y = next(iter(loader))\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    fig, axes = plt.subplots(len(eps_list), 6, figsize=(10, 6))\n",
    "    for row, eps in enumerate(eps_list):\n",
    "        adv = pgd_attack(model, x[:6], y[:6], eps, eps/4, iters=20)\n",
    "        for i in range(6):\n",
    "            axes[row, i].imshow(adv[i].detach().cpu().squeeze(), cmap=\"gray\")\n",
    "            axes[row, i].set_title(f\"ϵ={eps:.2f}\")\n",
    "            axes[row, i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_adversarial_examples(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
